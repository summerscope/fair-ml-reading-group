# Fair ML Reading Group 2021
üåè Melbourne, Australia  
üñ• Hosted remotely  
ü§ñ Facilitated by [Laura](https://twitter.com/summerscope)  
üì¨ Listserv at [groups.io/g/fair-ml](https://groups.io/g/fair-ml)  
üóì [Google calendar](https://calendar.google.com/calendar?cid=MWVxa29iam90NHB0YXMzNjQxZXRvN2lkZjhAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ)
 
## Description
A multi-disciplinary group reading papers on the topic of fairness and ethics in Machine Learning and Data Science. 

2020 papers ‚Äî [https://github.com/summerscope/fair-ml-reading-group/blob/master/2020.md](https://github.com/summerscope/fair-ml-reading-group/blob/master/2020.md)

2019 papers ‚Äî [https://github.com/summerscope/fair-ml-reading-group/blob/master/2019.md](https://github.com/summerscope/fair-ml-reading-group/blob/master/2019.md)

---
## Reading history

March 3    
**On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?**  
[http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf](http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf)  
  
March 18    
**"This Whole Thing Smacks of Gender": Algorithmic Exclusion in Bioimpedance-based Body Composition Analysis**  
[https://arxiv.org/abs/2101.08325](https://arxiv.org/abs/2101.08325)  
  
March 31    
**PROBAST: A Tool to Assess the Risk of Bias and Applicability of Prediction Model Studies**  
[https://www.researchgate.net/publication/330070686_PROBAST_A_Tool_to_Assess_the_Risk_of_Bias_and_Applicability_of_Prediction_Model_Studies](https://www.researchgate.net/publication/330070686_PROBAST_A_Tool_to_Assess_the_Risk_of_Bias_and_Applicability_of_Prediction_Model_Studies)  
  
_PROBAST in use_  
**Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans**  
[https://www.nature.com/articles/s42256-021-00307-0](https://www.nature.com/articles/s42256-021-00307-0)  
  
April 15    
**A Unified Approach to Interpreting Model Predictions** _(SHAP paper)_ 
[https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html)  
[https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)  

April 28  
**Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?**  
[https://arxiv.org/abs/1812.05239](https://arxiv.org/abs/1812.05239)  

May 13  
**Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI**  
[https://arxiv.org/abs/2010.07487](https://arxiv.org/abs/2010.07487)  
  
May 26   
**Explaining Machine Learning Predictions: State-of-the-art, Challenges, and Opportunities**  
[https://explainml-tutorial.github.io/aaai21](https://explainml-tutorial.github.io/aaai21) 
  
_Bonus Paper_   
**The Myth of Complete AI-Fairness**  
[https://arxiv.org/abs/2104.12544](https://arxiv.org/abs/2104.12544)  
  
June 10  
**Fair Bayesian Optimization**   
[https://arxiv.org/abs/2006.05109](https://arxiv.org/abs/2006.05109)  


